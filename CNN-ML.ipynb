{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8419926,"sourceType":"datasetVersion","datasetId":5012507},{"sourceId":8419939,"sourceType":"datasetVersion","datasetId":5012519},{"sourceId":8419956,"sourceType":"datasetVersion","datasetId":5012534},{"sourceId":8419968,"sourceType":"datasetVersion","datasetId":5012542},{"sourceId":8419979,"sourceType":"datasetVersion","datasetId":5012550},{"sourceId":8419983,"sourceType":"datasetVersion","datasetId":5012552},{"sourceId":8431353,"sourceType":"datasetVersion","datasetId":5021197},{"sourceId":8431520,"sourceType":"datasetVersion","datasetId":5021332},{"sourceId":8431512,"sourceType":"datasetVersion","datasetId":5021326},{"sourceId":8431526,"sourceType":"datasetVersion","datasetId":5021338},{"sourceId":8431538,"sourceType":"datasetVersion","datasetId":5021349},{"sourceId":8431543,"sourceType":"datasetVersion","datasetId":5021353},{"sourceId":8431548,"sourceType":"datasetVersion","datasetId":5021357},{"sourceId":8431552,"sourceType":"datasetVersion","datasetId":5021360},{"sourceId":8431557,"sourceType":"datasetVersion","datasetId":5021364},{"sourceId":8431564,"sourceType":"datasetVersion","datasetId":5021369},{"sourceId":8431570,"sourceType":"datasetVersion","datasetId":5021375},{"sourceId":8431573,"sourceType":"datasetVersion","datasetId":5021378}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import time\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import f1_score\n","from scipy.io import savemat, loadmat\n","\n","def main(scenario_name, snr_value, top_k=20):\n","    train_X = loadmat(f'/kaggle/input/{scenario_name}-{snr_value}-train/data.mat')['datat']\n","    train_Y = loadmat(f'/kaggle/input/{scenario_name}-{snr_value}-train-labels/labels.mat')['Labels']\n","    valid_X = loadmat(f'/kaggle/input/{scenario_name}-{snr_value}-valid/data.mat')['datat']\n","    valid_Y = loadmat(f'/kaggle/input/{scenario_name}-{snr_value}-valid-labels/labels.mat')['Labels']\n","    test_X = loadmat(f'/kaggle/input/{scenario_name}-{snr_value}-test/data.mat')['datat']\n","    test_Y = loadmat(f'/kaggle/input/{scenario_name}-{snr_value}-test-labels/labels.mat')['Labels']\n","\n","    # Reshape the data\n","    train_X = train_X.reshape((6000, 64, 4, 1))\n","    valid_X = valid_X.reshape((2000, 64, 4, 1))\n","    test_X = test_X.reshape((2000, 64, 4, 1))\n","\n","    # Define model\n","    model = Sequential([\n","        Conv2D(filters=16, kernel_size=(4, 4), strides=1, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n","        BatchNormalization(),\n","        Dropout(0.3),\n","        Conv2D(filters=16, kernel_size=(5, 5), strides=1, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n","        BatchNormalization(),\n","        Dropout(0.3),\n","        Flatten(),\n","        Dense(units=512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n","        BatchNormalization(),\n","        Dropout(0.3),\n","        Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n","        BatchNormalization(),\n","        Dropout(0.3),\n","        Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n","        BatchNormalization(),\n","        Dropout(0.3),\n","        Dense(units=64, activation='sigmoid')\n","    ])\n","\n","    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n","\n","    # Early stopping callback\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    model.fit(train_X, train_Y, epochs=50, validation_data=(valid_X, valid_Y), callbacks=[early_stopping])\n","\n","    start_time = time.time()\n","\n","    predicted_labels = model.predict(test_X)\n","\n","    # Sort predictions for each sample in descending order\n","    sorted_indices = np.argsort(-predicted_labels, axis=1)\n","\n","    # Initialize array to store top k labels for each sample\n","    selected_labels = np.zeros_like(test_Y)\n","\n","    for i in range(len(test_Y)):\n","        top_indices = sorted_indices[i, :top_k]\n","        # Sort the top indices to maintain the original order\n","        top_indices = np.sort(top_indices)\n","        selected_labels[i, top_indices] = 1\n","\n","    end_time = time.time()  # Record end time\n","    elapsed_time = end_time - start_time  # Calculate elapsed time\n","    print(elapsed_time)\n","\n","    print(selected_labels[:10])\n","\n","    directory = \"/kaggle/working/\"\n","\n","    # Ensure that the directory exists, create it if necessary\n","    os.makedirs(directory, exist_ok=True)\n","\n","    # Define the filename for the MATLAB file\n","    filename = f\"{scenario_name}_{snr_value}_predicted_labelcnn.mat\"\n","\n","    # Concatenate the directory path and filename\n","    filepath = os.path.join(directory, filename)\n","\n","    # Save the predicted labels to the MATLAB file\n","    try:\n","        savemat(filepath, {\"y_predcnn\": selected_labels})\n","    except Exception as e:\n","        print(\"Error saving file:\", e)\n","\n","    # Calculate the F1 score\n","    f1 = f1_score(test_Y, selected_labels, average='samples')  # Assuming 'y_test' contains the true labels\n","    print(\"F1 Score:\", f1)\n","\n","\n","if __name__ == \"__main__\":\n","    scenario_name = \"20\"\n","    snr_value = \"snr0\"\n","    main(scenario_name, snr_value, top_k=20)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-05-16T21:07:24.909522Z","iopub.execute_input":"2024-05-16T21:07:24.910018Z","iopub.status.idle":"2024-05-16T21:14:02.453435Z","shell.execute_reply.started":"2024-05-16T21:07:24.909981Z","shell.execute_reply":"2024-05-16T21:14:02.452069Z"},"trusted":true,"id":"9HmqIlVVsrlY","outputId":"1ef8709c-d8bd-44c9-e8bb-9dcf5f493c2b"},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.0145 - loss: 15.0303 - val_accuracy: 0.0075 - val_loss: 14.1066\nEpoch 2/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0178 - loss: 13.9904 - val_accuracy: 0.0085 - val_loss: 13.1414\nEpoch 3/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0192 - loss: 13.0292 - val_accuracy: 0.0190 - val_loss: 12.2345\nEpoch 4/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.0174 - loss: 12.1339 - val_accuracy: 0.0315 - val_loss: 11.3901\nEpoch 5/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0189 - loss: 11.3014 - val_accuracy: 0.0440 - val_loss: 10.6092\nEpoch 6/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0191 - loss: 10.5295 - val_accuracy: 0.0285 - val_loss: 9.8793\nEpoch 7/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0197 - loss: 9.8106 - val_accuracy: 0.0690 - val_loss: 9.2047\nEpoch 8/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0275 - loss: 9.1439 - val_accuracy: 0.0915 - val_loss: 8.5812\nEpoch 9/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0259 - loss: 8.5223 - val_accuracy: 0.0620 - val_loss: 8.0001\nEpoch 10/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0275 - loss: 7.9451 - val_accuracy: 0.0670 - val_loss: 7.4614\nEpoch 11/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0269 - loss: 7.4133 - val_accuracy: 0.1350 - val_loss: 6.9617\nEpoch 12/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.0343 - loss: 6.9139 - val_accuracy: 0.1665 - val_loss: 6.4957\nEpoch 13/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0273 - loss: 6.4548 - val_accuracy: 0.1780 - val_loss: 6.0656\nEpoch 14/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0339 - loss: 6.0256 - val_accuracy: 0.1670 - val_loss: 5.6653\nEpoch 15/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0365 - loss: 5.6264 - val_accuracy: 0.1625 - val_loss: 5.2940\nEpoch 16/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.0377 - loss: 5.2601 - val_accuracy: 0.2045 - val_loss: 4.9489\nEpoch 17/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.0449 - loss: 4.9149 - val_accuracy: 0.2060 - val_loss: 4.6299\nEpoch 18/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.0419 - loss: 4.5985 - val_accuracy: 0.1465 - val_loss: 4.3320\nEpoch 19/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0522 - loss: 4.3015 - val_accuracy: 0.1395 - val_loss: 4.0568\nEpoch 20/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.0568 - loss: 4.0288 - val_accuracy: 0.1210 - val_loss: 3.8006\nEpoch 21/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.0638 - loss: 3.7745 - val_accuracy: 0.1215 - val_loss: 3.5635\nEpoch 22/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0694 - loss: 3.5373 - val_accuracy: 0.1340 - val_loss: 3.3430\nEpoch 23/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0752 - loss: 3.3208 - val_accuracy: 0.1395 - val_loss: 3.1383\nEpoch 24/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.0787 - loss: 3.1167 - val_accuracy: 0.1260 - val_loss: 2.9480\nEpoch 25/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0894 - loss: 2.9259 - val_accuracy: 0.1275 - val_loss: 2.7723\nEpoch 26/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0881 - loss: 2.7512 - val_accuracy: 0.1170 - val_loss: 2.6085\nEpoch 27/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0968 - loss: 2.5892 - val_accuracy: 0.1160 - val_loss: 2.4567\nEpoch 28/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1021 - loss: 2.4375 - val_accuracy: 0.1190 - val_loss: 2.3159\nEpoch 29/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.1063 - loss: 2.2969 - val_accuracy: 0.1190 - val_loss: 2.1856\nEpoch 30/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1073 - loss: 2.1653 - val_accuracy: 0.1160 - val_loss: 2.0646\nEpoch 31/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.1050 - loss: 2.0460 - val_accuracy: 0.1200 - val_loss: 1.9525\nEpoch 32/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.1234 - loss: 1.9338 - val_accuracy: 0.1255 - val_loss: 1.8487\nEpoch 33/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.1202 - loss: 1.8321 - val_accuracy: 0.1220 - val_loss: 1.7526\nEpoch 34/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.1117 - loss: 1.7347 - val_accuracy: 0.1170 - val_loss: 1.6633\nEpoch 35/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1303 - loss: 1.6481 - val_accuracy: 0.1160 - val_loss: 1.5807\nEpoch 36/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.1280 - loss: 1.5642 - val_accuracy: 0.1135 - val_loss: 1.5039\nEpoch 37/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.1276 - loss: 1.4870 - val_accuracy: 0.1150 - val_loss: 1.4330\nEpoch 38/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.1308 - loss: 1.4163 - val_accuracy: 0.1125 - val_loss: 1.3674\nEpoch 39/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1421 - loss: 1.3498 - val_accuracy: 0.1130 - val_loss: 1.3063\nEpoch 40/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.1423 - loss: 1.2892 - val_accuracy: 0.1145 - val_loss: 1.2498\nEpoch 41/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.1449 - loss: 1.2319 - val_accuracy: 0.1115 - val_loss: 1.1975\nEpoch 42/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.1483 - loss: 1.1785 - val_accuracy: 0.1110 - val_loss: 1.1492\nEpoch 43/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.1501 - loss: 1.1325 - val_accuracy: 0.1145 - val_loss: 1.1042\nEpoch 44/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.1425 - loss: 1.0862 - val_accuracy: 0.1165 - val_loss: 1.0625\nEpoch 45/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1591 - loss: 1.0433 - val_accuracy: 0.1290 - val_loss: 1.0240\nEpoch 46/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.1694 - loss: 1.0059 - val_accuracy: 0.1300 - val_loss: 0.9883\nEpoch 47/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1596 - loss: 0.9707 - val_accuracy: 0.1285 - val_loss: 0.9551\nEpoch 48/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.1622 - loss: 0.9355 - val_accuracy: 0.1280 - val_loss: 0.9244\nEpoch 49/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.1753 - loss: 0.9032 - val_accuracy: 0.1265 - val_loss: 0.8959\nEpoch 50/50\n\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.1717 - loss: 0.8755 - val_accuracy: 0.1320 - val_loss: 0.8694\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n1.3428409099578857\n[[1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 0 1 1 1]\n [1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 1 1 1]]\nF1 Score: 0.561704467312747\n","output_type":"stream"}]}]}